vlines
component_levels <- levels(factor(combined_table$Component))
vlines$y <- match(vlines$Component, component_levels)
# Horizontal, no label, but has No
p <- ggplot(data = combined_table) +
geom_bar(
aes(y = Component, x = Count, fill = Presence),
stat = "identity",
position = "fill"
) +
geom_segment(
data = vlines,
aes(
x = x, xend = x,
y = as.numeric(Component) - 0.45,
yend = as.numeric(Component) + 0.45
),
linetype = "dotted",
linewidth = 1
) +
geom_text(
aes(y = Component, x = Count, label = label, fill = Presence),
stat = "identity",
position = position_fill(vjust = 0.5),
color = "white",
fontface = "bold",
size = 5
) +
labs(y = "Component", x = "Proportion of Participants") +
theme_minimal() +
scale_fill_brewer(palette = "Set2") +
scale_fill_manual(values = c("Yes" = "#66c2a5", "No" = "#fc8d62")) +
theme(
legend.position = "none",
axis.text.y = element_blank(),
axis.text = element_text(size = 14),
axis.title = element_text(size = 18)
) # This looks like the best way to get size right in saving plots
print(p)
component_levels <- sort(unique(combined_table$Component))
component_levels
vlines$y <- match(vlines$Component, component_levels)
p <- ggplot(data = combined_table) +
geom_bar(
aes(y = Component, x = Count, fill = Presence),
stat = "identity",
position = "fill"
) +
geom_segment(
data = vlines,
aes(
x = x, xend = x,
y = y - 0.45,
yend = y + 0.45
),
linetype = "dotted",
linewidth = 1
) +
scale_y_discrete(limits = component_levels) +   # <-- important
geom_text(
aes(y = Component, x = Count, label = label, fill = Presence),
stat = "identity",
position = position_fill(vjust = 0.5),
color = "white",
fontface = "bold",
size = 5
) +
labs(y = "Component", x = "Proportion of Participants") +
theme_minimal()
print(p)
# Horizontal, no label, but has No
p <- ggplot(data = combined_table) +
geom_bar(
aes(y = Component, x = Count, fill = Presence),
stat = "identity",
position = "fill"
) +
geom_segment(
data = vlines,
aes(
x = x, xend = x,
y = as.numeric(Component) - 0.45,
yend = as.numeric(Component) + 0.45
),
linetype = "dotted",
linewidth = 1
) +
scale_y_discrete(limits = component_levels) +
geom_text(
aes(y = Component, x = Count, label = label, fill = Presence),
stat = "identity",
position = position_fill(vjust = 0.5),
color = "white",
fontface = "bold",
size = 5
) +
labs(y = "Component", x = "Proportion of Participants") +
theme_minimal() +
scale_fill_brewer(palette = "Set2") +
scale_fill_manual(values = c("Yes" = "#66c2a5", "No" = "#fc8d62")) +
theme(
legend.position = "none",
axis.text.y = element_blank(),
axis.text = element_text(size = 14),
axis.title = element_text(size = 18)
) # This looks like the best way to get size right in saving plots
print(p)
# Horizontal, no label, but has No
p <- ggplot(data = combined_table) +
geom_bar(
aes(y = Component, x = Count, fill = Presence),
stat = "identity",
position = "fill"
) +
geom_segment(
data = vlines,
aes(
x = x, xend = x,
y = y - 0.45,
yend = y + 0.45
),
linetype = "dotted",
linewidth = 1
) +
scale_y_discrete(limits = component_levels) +
geom_text(
aes(y = Component, x = Count, label = label, fill = Presence),
stat = "identity",
position = position_fill(vjust = 0.5),
color = "white",
fontface = "bold",
size = 5
) +
labs(y = "Component", x = "Proportion of Participants") +
theme_minimal() +
scale_fill_brewer(palette = "Set2") +
scale_fill_manual(values = c("Yes" = "#66c2a5", "No" = "#fc8d62")) +
theme(
legend.position = "none",
axis.text.y = element_blank(),
axis.text = element_text(size = 14),
axis.title = element_text(size = 18)
) # This looks like the best way to get size right in saving plots
print(p)
ggsave(
filename = "bestByComponent.pdf",
plot = p,
path = here("Other", "Plots"),
width = 12,
#height = 8,
units = "in"
)
str(noInf_table)
chisq_test_noInf <- chisq.test(noInf_table$participant_count, p = c(0.667, 0.333))
print(chisq_test_noInf) # x 1.69, p.19, no difference
chisq_test_noAct <- chisq.test(noAct_table$participant_count, p = c(0.5, 0.5))
print(chisq_test_noAct) # x 3, p .08, no difference
View(noInf_table)
View(noAct_table)
View(noKind_table)
View(noSelect_table)
chisq_test_noSelect <- chisq.test(
noSelect_table$participant_count,
p = c(0.5, 0.5)
)
print(chisq_test_noSelect) # x 30.1, p4.14e-8, significant difference
chisq_test_noInf <- chisq.test(noInf_table$participant_count, p = c(0.667, 0.333))
print(chisq_test_noInf) # x 6.23, p.013, no difference
# (THE MODELS ARENT USED HERE, JUST FOR HANDY GROUPED PPT VALUES SO DOESNT VARY WITH MODELS, DOESNT NEED OT BE THE LATEST)
load(here('Data', 'modelData', 'modelAndDataUnfitig.rda')) # df, 288 of 23
# Split df into 3, on pgroup
df_p1 <- df |>
filter(pgroup == 1) |>
select(pgroup, trialtype, node3, n) |>
# Concatenate trialtype and node3 into a new variable in a new column
mutate(trial_node = paste(trialtype, node3, sep = "_"))
df_p2 <- df |>
filter(pgroup == 2) |>
select(pgroup, trialtype, node3, n) |>
# Concatenate trialtype and node3 into a new variable in a new column
mutate(trial_node = paste(trialtype, node3, sep = "_"))
df_p3 <- df |>
filter(pgroup == 3) |>
select(pgroup, trialtype, node3, n) |>
# Concatenate trialtype and node3 into a new variable in a new column
mutate(trial_node = paste(trialtype, node3, sep = "_"))
trialnodes <- unique(df_p1$trial_node)
# Merge these three dataframes on trial_node to make a 3-way composite for chisq tests
fortest <- df_p1 |>
inner_join(df_p2, by = "trial_node", suffix = c("_1", "_2")) |>
inner_join(df_p3, by = "trial_node") |> #, suffix = ("_3")
rename(n1 = n_1, n2 = n_2, n3 = n) |>
select(n1, n2, n3)
fortest_nonzero <- fortest[rowSums(fortest) > 0, ]
omnibus <- chisq.test(fortest_nonzero) # X = 238.8, df = 186, p= .005411
print(omnibus)
View(fortest_nonzero)
nom <- sum(fortest_nonzero) # 1713
om13 <- sqrt((ch13$statistic / n13)) # .246
om <- sqrt((omnibus$statistic / nom)) # .373 medium effect size
om <- sqrt(omnibus$statistic / (nom*2)) # .304 medium effect size
library(here)
library(tidyverse)
load(here('Data', 'modelData', 'fitforplot25.rda')) # 288 of 43. Pre 3 Nov: 288 of 35 fitforplot16k.rda
View(df)
# The tag 'Known' should no longer apply to Observed vars.
# If node3 starts with A= or B= then replace Known with FALSE
df <- df |>
mutate(
Known = ifelse(
str_starts(node3, "A=") | str_starts(node3, "B="),
FALSE,
Known
)
)
View(df)
load(here('Data', 'modelData', 'fitforplot25.rda')) # 288 of 43. Pre 3 Nov: 288 of 35 fitforplot16k.rda
# The tag 'Known' should no longer apply to Observed vars.
# If node3 starts with A= or B= then put FALSE in the column Known
vals <- c("A=0", "A=1", "B=0", "B=1")
View(df)
# If node3 %in% vals, then Known = FALSE
df$Known[df$node3 %in% vals] <- FALSE
# 1. Gather and calculate mean and SE per group - 576 of 5
df_long0 <- df |>
select(trial_id, node3, prop, full_ig, Known) |>
gather(key, val, prop:full_ig) |>
filter(!is.na(val)) |>
mutate(
key = factor(
key,
levels = c("full_ig", "prop"),
labels = c("Model", "Participants")
)
)
summary_df0 <- df_long0 |>
group_by(Known, key) |>
summarise(
val_sum = sum(val),
se = sd(val) / sqrt(n())
) |>
mutate(val = val_sum / 36) |>
select(-val_sum) |>
ungroup()
# 2. Plot with bars and error bars
pknown <- ggplot(summary_df0, aes(x = key, y = val, fill = Known)) +
geom_bar(stat = "identity", position = position_dodge(0.9)) +
geom_errorbar(
aes(ymin = val - se, ymax = val + se),
width = 0.2,
position = position_dodge(0.9)
) +
labs(x = "Response", y = "Proportion/Prediction", fill = "Known status") +
scale_fill_brewer(palette = "Set2") + #, labels = c("", "") +
scale_fill_manual(values = c("TRUE" = "#66c2a5", "FALSE" = "#fc8d62")) +
theme_bw() +
theme(
panel.grid = element_blank(),
legend.text = element_text(size = 10),
legend.title = element_text(size = 10)
)
# A version with *** added, although now with new model no use
pknown <- ggplot(summary_df0, aes(x = key, y = val, fill = Known)) +
geom_bar(stat = "identity", position = position_dodge(0.9)) +
geom_errorbar(
aes(ymin = val - se, ymax = val + se),
width = 0.2,
position = position_dodge(0.9)
) +
annotate(
"text",
x = 1.5,
y = max(summary_df0$val + summary_df0$se) + 0.05,
label = "***",
hjust = 0.5,
vjust = 0.5,
size = 5
) +
labs(x = "Response", y = "Proportion/Prediction", fill = "Known") +
scale_fill_brewer(palette = "Set2") +
scale_fill_manual(values = c("TRUE" = "#66c2a5", "FALSE" = "#fc8d62")) +
theme_bw() +
theme(
panel.grid = element_blank(),
legend.text = element_text(size = 10),
legend.title = element_text(size = 10)
)
print(pknown)
# Load
load(here('Data', 'modelData', 'matchedBypptf_ig.rda')) # loads merged 5160 of 14
View(merged)
# The tag 'Known' should no longer apply to Observed vars.
# If node3 starts with A= or B= then put FALSE in the column Known
vals <- c("A=0", "A=1", "B=0", "B=1")
# If node3 %in% vals, then Known = FALSE
merged$Known[merged$Response %in% vals] <- FALSE
countKnown <- merged |> # F: 2247, T: 2913, answer T 56.5% of the time
group_by(Known) |>
summarise(n = n())
View(countKnown)
View(merged)
View(merged)
predKn <- glmer(
Known ~ Respondent + (1 | subject_id) + (1 | trial_id),
data = merged,
family = binomial(link = 'logit')
)
library(lme4)
library(lmerTest)
predKn <- glmer(
Known ~ Respondent + (1 | subject_id) + (1 | trial_id),
data = merged,
family = binomial(link = 'logit')
)
summary(predKn)
coef <- fixef(predKn) # .292
est <- exp(coef) # 1.34 - exp converts logodds to odds.
se <- sqrt(diag(vcov(predKn)))
lower_logodds <- coef - (1.96 * se)
upper_logodds <- coef + (1.96 * se)
lower_or <- exp(lower_logodds) # 1.182
upper_or <- exp(upper_logodds) # 1.52
#   summarise(n = n())
#
# chisq.test(countObs$n, p = c(0.5, 0.5)) # X-squared 133.51, df 1, p < 2.2e-16 ***
#
# countAct <- merged |> # F: 1186, T: 3974, answer T 77.0% of the time
#   group_by(Actual) |>
#   summarise(n = n())
#
# chisq.test(countAct$n, p = c(180 / 288, 108 / 288)) # 3437.7, 1, p < 2.2e-16 ***
#
countKnown <- merged |> # F: 2247, T: 2913, answer T 56.5% of the time
filter(Respondent == "node3") |>
group_by(Known) |>
summarise(n = n())
View(countKnown)
#   summarise(n = n())
#
# chisq.test(countObs$n, p = c(0.5, 0.5)) # X-squared 133.51, df 1, p < 2.2e-16 ***
#
# countAct <- merged |> # F: 1186, T: 3974, answer T 77.0% of the time
#   group_by(Actual) |>
#   summarise(n = n())
#
# chisq.test(countAct$n, p = c(180 / 288, 108 / 288)) # 3437.7, 1, p < 2.2e-16 ***
#
countKnown <- merged |> # F: 2247, T: 2913, answer T 56.5% of the time
#filter(Respondent == "node3") |>
group_by(Respondent, Known) |>
summarise(n = n())
View(countKnown)
#   summarise(n = n())
#
# chisq.test(countObs$n, p = c(0.5, 0.5)) # X-squared 133.51, df 1, p < 2.2e-16 ***
#
# countAct <- merged |> # F: 1186, T: 3974, answer T 77.0% of the time
#   group_by(Actual) |>
#   summarise(n = n())
#
# chisq.test(countAct$n, p = c(180 / 288, 108 / 288)) # 3437.7, 1, p < 2.2e-16 ***
#
countKnown <- merged |> # F: 2247, T: 2913, answer T 56.5% of the time
filter(Respondent == "node3") |>
group_by(Known) |>
summarise(n = n())
View(countKnown)
View(countKnown)
countObs <- merged |> # F: 2995, T: 2165, answer F 58.0% of the time
filter(Respondent == "node3") |>
group_by(Observed) |>
summarise(n = n())
chisq.test(countObs$n, p = c(0.5, 0.5)) # X-squared 133.51, df 1, p < 2.2e-16 ***
View(countObs)
library(here)
library(tidyverse)
load(here('Data', 'modelData', 'modelproc.rda')) # loads mp 576 obs of 23
load(here('Data', 'Data.rdata')) # loads data 2580 obs of 23
# Condition 1
mp <- mp |> #
mutate(
Actual = case_when(
node2 == 'A' ~ A == E.x,
node2 == 'B' ~ B == E.x,
node2 == 'Au' ~ Au == E.x,
node2 == 'Bu' ~ Bu == E.x
)
)
# Condition 2 - many of these are already caught but just to catch the extras
mp$Actual[mp$A == '0' & mp$node3 == 'Au=1'] <- FALSE
mp$Actual[mp$B == '0' & mp$node3 == 'Bu=1'] <- FALSE
mp <- mp |>
mutate(cesmActual = cesm * Actual)
# [CES_{Au=1|Bu=1}*P(Bu=1|Au=1) + CES_{Au=1|Bu=0}P(Bu=0|Au=1)] * P(Au=1)
# or [CES_{Au=1|Bu=1}*P(Bu=1 & Au=1) + CES_{Au=1|Bu=0}P(Bu=0 & Au=1)]
full <- mp |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(full = sum(cesmActual * posterior))
noAct <- mp |> #2
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noAct = sum(cesm * posterior))
# Uses the cesm after treatment for Actuality, but then uses prior of unobserved variables rather than posterior
noInf <- mp |> #3
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noInf = sum(cesmActual * PrUn))
# Uses plain cesm before treatment for Actual, and prior of unobserved variables rather than posterior
noActnoInf <- mp |> #6
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noActnoInf = sum(cesm * PrUn))
getpost <- mp |>
filter(!node2 %in% c('A', 'B')) |>
group_by(pgroup, trialtype, node3, .drop = F) |> # if we need Eig then go back and group by node2
summarise(post = sum(posterior), prior = sum(PrUn))
# Simple ig of each pair of unobserved vars
unobs_ig <- getpost |>
group_by(pgroup, trialtype, node3) |> # if we need eig then go back and group by node2
summarise(
prior_entropy = round(-sum(prior * log2(prior + 1e-10)), 3),
post_entropy = round(-sum(post * log2(post + 1e-10)), 3),
ig = round(prior_entropy - post_entropy, 3)
) |>
ungroup()
# Merge only column ig of unobs_ig with mp to get postig
ig <- unobs_ig |>
select(pgroup, trialtype, node3, ig)
postigi <- merge(
mp,
getpost,
by = c('pgroup', 'trialtype', 'node3'),
all.x = TRUE
)
postig <- merge(
postigi,
ig,
by = c('pgroup', 'trialtype', 'node3'),
all.x = TRUE
)
# Test noSelect
noSelect_test <- mp |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noSelect_test = sum(Actual * posterior))
View(noSelect_test)
noSelect <- postig |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noSelect = mean(noSelect)) # These are meant to be mean, even though full is sum, because the same value is listed several times, one for each combination of unobs vars
# An intermediate measure: For A and B, gives 1 when E matches, 0 if not. This sets B to 1 for actual cause, eg. if B=0 when E=0
postig <- postig |>
mutate(
Act1 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post,
node2 == 'Bu' ~ post
)
)
postig <- postig |>
mutate(
noSelect = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post * Actual,
node2 == 'Bu' ~ post * Actual
)
)
noSelect <- postig |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noSelect = mean(noSelect)) # These are meant to be mean, even though full is sum, because the same value is listed several times, one for each combination of unobs vars
View(noSelect)
View(full)
View(mp)
View(full)
View(full)
library(here)
library(tidyverse)
load(here('Data', 'modelData', 'modelproc.rda')) # loads mp 576 obs of 23
load(here('Data', 'Data.rdata')) # loads data 2580 obs of 23
# Condition 1
mp <- mp |> #
mutate(
Actual = case_when(
node2 == 'A' ~ A == E.x,
node2 == 'B' ~ B == E.x,
node2 == 'Au' ~ Au == E.x,
node2 == 'Bu' ~ Bu == E.x
)
)
# Condition 2 - many of these are already caught but just to catch the extras
mp$Actual[mp$A == '0' & mp$node3 == 'Au=1'] <- FALSE
mp$Actual[mp$B == '0' & mp$node3 == 'Bu=1'] <- FALSE
mp <- mp |>
mutate(cesmActual = cesm * Actual)
# [CES_{Au=1|Bu=1}*P(Bu=1|Au=1) + CES_{Au=1|Bu=0}P(Bu=0|Au=1)] * P(Au=1)
# or [CES_{Au=1|Bu=1}*P(Bu=1 & Au=1) + CES_{Au=1|Bu=0}P(Bu=0 & Au=1)]
full <- mp |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(full = sum(cesmActual * posterior))
View(full)
# Test noSelect
noSelect_test <- mp |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noSelect_test = sum(Actual * posterior))
View(noSelect_test)
library(here)
library(tidyverse)
load(here('Data', 'modelData', 'modelAndDataUnfitig.rda')) # df, 288 of 23
View(df)
source(here('Scripts', 'optimUtilsNNN4.R')) # functions to optimise
set.seed(12)
# Run the series of optimisation functions from the utils file
results1 <- get_optimisation(model_names, df, operative = WITH_KAPPA)
View(df)
View(df)
