View(case)
dependence<-p_actual-p_counterfactual
#In this case we might reasonably blame her lazy character or the fact that the pizza was closer
Collapse
View(case)
View(pChoice)
dependence
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_push * char_push
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
pref_match_hotdog <- as.numeric(pChoice$Preference=='Hotdog')
char_match_hotdog <- as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Hotdog' |
pChoice$Character=='Sporty' & pChoice$Closer=='Pizza')
char_match_pizza <- as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Pizza' |
#character match to distance to pizza pushes toward pizza
pChoice$Character=='Sporty' & pChoice$Closer=='Hotdog')
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
#preference and character match only promote hotdog choice so long as the person either
#(a) knows the area or (b) can see the hotdog ie generative ie things that make you want hotdog
prom_hotdog <- pChoice$Knowledge=='Yes' | pChoice$Visible=='Hotdog'
#character match only promotes pizza choice so long as the person
#(a) knows the area or (b) can see the hotdog ie preventative factor ie things that amke you want pizza
prom_pizza <- pChoice$Knowledge=='Yes' | pChoice$Visible=='Pizza'
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_push * char_push
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(strengths[['character']], strengths[['preference']], baserate))
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate))
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate))
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate)))
# My meddling
hotdog_promotion <- function() {
pref_prom_hotdog <- 1 - strengths[['preference']] * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - strengths[['character']] * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion())
# My meddling
hotdog_promotion <- function() {
pref_prom_hotdog <- 1 - strengths[['preference']] * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - strengths[['character']] * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1- strengths[['character']] *char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion())
22/110
2.002/10.10
5.005/10.01
2.005/10.1
2.002/10.1
52/110
exp(100)
exp(1)
runif(4)
sessionInfo()
sessionInfo()
sessionInfo()
install.packages("afex")
install.packages("faux")
library(broom, tidyverse, faux, afex)
library(broom)
library(faux)
library(afex)
R.version()
R.Version()
.libPaths()
.libPaths()
R.Version()
# ------- Prelims -----------
library(tidyverse)
library(ggplot2)
# ----------- Define an example prior df -------------------------
# Here define two causal vars and an exogenous noise variable for each (i.e. var epsilon A goes with A)
# in the exp setting this is 0.5
p_A <- c(.1,.9) # ie A usually has value 1... base rate for cause
p_epsA <- c(.7,.3) #... most of the time the noise var for a doesn't occur. for a to work it needs a and exp a. a is usually present but ogten doesnt work cos of noise term not working
p_B <- c(.8,.2) # B rarely fires 1...
p_epsB <- c(.3,.7) # but when it does it is strong
# And wrap them into a df called prior. Later the function should take dfs of this format:
# i.e. any number of causes as the rows, and the probs of them taking 0 and 1 as cols
params <- data.frame(rbind(p_A, p_epsA, p_B, p_epsB))
colnames(params) <- c(0,1)
# Other values set outside for now
N_cf <- 1000L # How many counterfactual samples to draw
s <- .7 # Stability
n_causes <- nrow(params)
causes <- rownames(params)
# Make a df of all combinations of variable settings
df <- expand.grid(rep(list(c(0,1)),n_causes), KEEP.OUT.ATTRS = F)
# ... with variables as the column names
colnames(df) <- causes
worlds <- nrow(df)
View(df)
structure <- 'disjunctive'
if (structure=="disjunctive") {
df$E <- as.numeric((df[1] & df[2]) | (df[3] & df[4]))
}
# Can replace with this - if rename - it is deterministic - literally gives specific outcome for set 3 causes, needs actual input. mechanical tell syou whether effects occurred given setting
# df$effect <- max( c(min(c1,e1), min(c2,e2), min(c3, e3), min(c2*c3, e23))) # BUT SAME PROBLEM - HOW TO AUTOMATICALLY DEAL WITH ANY NUMBER OF CAUSES?
mat <- as.matrix(df[,1:4])
View(mat)
# df2 <- as.matrix(df, dimnames=NULL)
# dimnames = list(c(1:16), c(causes))
# Replace every cell with the relevant indexed edge strength from params
for (k in 1:worlds){
for (cause in causes) {
a <- params[cause,df[k,cause]+1] # It needs the '+1' because r indexes from 1 not 0
mat[k,cause] <- a # ((then sometimes #*df[k,cause] if do at same time as structure but change later if need))
}
}
View(mat)
View(params)
# For each row of df, the prior is now the product of the same row of df2
df$Pr <- apply(mat, 1, prod) # parameter of the model
sum(df$Pr)
# Then loop to calculate cfs and assign causal responsibility
# Loop through possible world settings
for (c_ix in 1:worlds)
sd(3000)
?rbinom
N <- 10^4
rbinom(N,1,.3)
sd_v <- sd(v)
v <- rbinom(N,1,.3)
sd_v <- sd(v)
?sd
th <- 0.3*0.7
p <- 0.3
derived <- (N*p(1-p))^0.5
derived <- (N*p*(1-p))^0.5
derived <- (N*3000*(1-p))^0.5
(p*(1-p)/n)^0.5
(p*(1-p)/N)^0.5
((p*(1-p))/N)^0.5
sum(v)
((3050*(6950))/N)^0.5
(N*p*(1-p))^0.5
q <- 0.7
p*q
0.3*0.7
N*p*q
2100^0.5
sqrt(2100)
(p*q/N)^0.5
((p*q)/N)^0.5
0.198^0.5
pest <- mean(v)
var <- (pest*(1-pest))/N
sqrt(var)
n <- 100
p*q/n
sqrt(p*q/n)
v2 <- rbinom(n,1,.3)
sd(v2)
sqrt(p*q)
sd(pest*(1-pest))
n2 <- 100000
v3 <- rbinom(n2,1,.3)
sd(v3)
sd(v2)
sd(v)
sum(v)
mean(v)
r <- mean(v)
g <- 1-r
sqrt(r*g)
?file.access
install.packages("gander")
usethis::edit_r_environ()
usethis::edit_r_profile()
library(ggplot2)
library(gander)
install.packages('ellmer')
library(ellmer)
library(ellmer)
library(gander)
data("stackoverflow", package = "modeldata")
stackoverflow
```r
stackoverflow %>%
summarise(across(where(is.numeric), list(mean = mean, sd = sd), na.rm = TRUE))
usethis::edit_r_profile()
usethis::edit_r_profile()
setwd("~/Documents/GitHub/gw/Exp1Prediction/Experiment/Scripts")
# Load df 1421 of 27. Each row is one participant's response to one of the 16 situations. Was 1440 but 19 had 0s so were removed.
load('../Data/gwExp1data.Rda')
View(df)
# For any plotting we need a long version of participants' actual ratings on a 1:7 Likert scale - 5684
forscatter_long <- df |>
select(mindsCode, lik_short_pizza:lik_long_hotdog, Situation) |>
pivot_longer(
cols = lik_short_pizza:lik_long_hotdog,
names_to = "Choice",
values_to = "Rating"
)
library(tidyverse)
# For any plotting we need a long version of participants' actual ratings on a 1:7 Likert scale - 5684
forscatter_long <- df |>
select(mindsCode, lik_short_pizza:lik_long_hotdog, Situation) |>
pivot_longer(
cols = lik_short_pizza:lik_long_hotdog,
names_to = "Choice",
values_to = "Rating"
)
View(forscatter_long)
setwd("~/Documents/GitHub/gw/Exp1Prediction/Model/Scripts")
# Load df 1421 of 27. Each row is one participant's response to one of the 16 situations. Was 1440 but 19 had 0s so were removed.
load('../../Experiment/Data/gwExp1data.Rda')
# Get the complete target distribution over all outcomes: 16 of 5, then lose first column
td <- df |>
group_by(Situation) |>
summarise(p_short_pizza = mean(p_short_pizza, na.rm=T),
p_long_pizza = mean(p_long_pizza, na.rm=T),
p_short_hotdog = mean(p_short_hotdog, na.rm=T),
p_long_hotdog = mean(p_long_hotdog, na.rm=T)) |>
data.frame()
View(td)
View(td)
max(td)
str(td)
max(td$p_long_hotdog)
print(max(td$p_short_pizza)) # 0.042
print(max(td$p_long_pizza)) # 0.042
print(max(td$p_short_hotdog)) # 0.042
print(min(td$p_long_hotdog)) # .30
print(min(td$p_short_pizza)) # .48
print(min(td$p_long_pizza)) # .26
print(min(td$p_short_hotdog)) # .52
setwd("~/Documents/GitHub/Collider_cognition/Scripts")
source(knitr::purl('modelCombLesions.Rmd')) # puts the processed model predictions together with lesions to get a df called 'modelAndDataUnfit.csv'
formatR::tidy_pipe()
##################################################################
######## Get lesions and combine with data ############
library(tidyverse)
library(stringr)
rm(list=ls())
# Script takes the processed data from the collider ppt expt (`DATA.RDATA`)
# and combines it with the pre-processed model predictions to get all the other model modules and lesions
load('../Data/Data.Rdata', verbose = T) # This is one big df, 'data', 2580, of 215 ppts
data <- df2
mp <- read.csv('../Data/modelData/tidied_predpn.csv') # 576 of 26 - 576 rows because: 3 pgroups x 12 trialtypes x 4 nodes x 4 prior possible settings of unobserved variables
mp$pgroup <- as.factor(mp$pgroup)
mp$node3 <- as.factor(mp$node3)
mp$trialtype <- as.factor(mp$trialtype)
mp$structure <- as.factor(mp$structure)
mp$E.x <- as.factor(mp$E.x)
mp$E.y <- as.factor(mp$E.y)
# TO DO later - get the comments from the Rmd file and put them in here as well
# Condition 1
mp <- mp |> #
mutate(Actual = case_when(
node2 == 'A' ~ A==E.x,
node2 == 'B' ~ B==E.x,
node2 == 'Au' ~ Au==E.x,
node2 == 'Bu' ~ Bu==E.x
))
# Condition 2 - many of these are already caught but just to catch the extras
mp$Actual[mp$A=='0' & mp$node3=='Au=1'] <- FALSE
mp$Actual[mp$B=='0' & mp$node3=='Bu=1'] <- FALSE
mp <- mp |>
mutate(cesmActual = cesm*Actual)
# FULL inc kindness #1
full <- mp |>  #1
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(full = sum(cesmActual*posterior))
# Unnormalised of course and not incorporating K / EMD yet
noAct <- mp |>  #2
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noAct = sum(cesm*posterior))
noInf <- mp |>  #3
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noInf = sum(cesmActual*PrUn))
noActnoInf <- mp |>  #6
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noActnoInf = sum(cesm*PrUn))
getpost <- mp |> # 120 obs of 4
filter(!node2 %in% c('A','B')) |> #
group_by(pgroup, trialtype, node) |>
summarise(post = sum(posterior),
prior = sum(PrUn),
tv = round(abs((post-prior)),3)) # Maybe don't divide here by 2? Because both Au=1 and Au=0 need the value separately
postmp <- merge(mp, getpost, by = c('pgroup', 'trialtype', 'node'), all.x = TRUE)
# For A and B, gives 1 when E matches, 0 if not. This sets B to 1 for actual cause, eg. if B=0 when E=0
postmp <- postmp |>
mutate(Act1 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post,
node2 == 'Bu' ~ post
))
postmp <- postmp |>
mutate(noSelect = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post*Actual,
node2 == 'Bu' ~ post*Actual
))
noSelect <- postmp |> #14
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noSelect = mean(noSelect))
noActnoSelect <- postmp |> #14
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noActnoSelect = mean(Act1))
mp <- mp |>
mutate(Act3 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ peA*Actual,
node2 == 'Bu' ~ peB*Actual
))
noInfnoSelect <- mp |> #10
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noInfnoSelect = mean(Act3))
mp <- mp |> #
mutate(Act2 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ peA,
node2 == 'Bu' ~ peB
))
noActnoInfnoSelect <- mp |> # no act here means for the unobserved variables
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noActnoInfnoSelect = mean(Act2))
df_list <- list(full,
noAct,
noInf,
noSelect,
noActnoInf,
noActnoSelect,
noInfnoSelect,
noActnoInfnoSelect)
models <- df_list |> reduce(full_join, by = c('pgroup', 'trialtype', 'node3'))
Actual <- mp |> select(pgroup, trialtype, node3, Actual) |> unique()
models2 <- merge(models, Actual, all.x = TRUE)
# ------------- 2. Summarise participant data in same format ---------------------
# First set factors so we can use tally
data$pgroup <- as.factor(data$pgroup)
data$node3 <- as.factor(data$node3)
data$trialtype <- as.factor(data$trialtype)
dataNorm <- data |> # 289
group_by(pgroup, trialtype, node3, .drop=FALSE) |> # Here we do need the .drop to get all the combinations
tally |>
mutate(prop=n/sum(n))
##################################################################
######## Get lesions and combine with data ############
library(tidyverse)
library(stringr)
rm(list=ls())
# Script takes the processed data from the collider ppt expt (`DATA.RDATA`)
# and combines it with the pre-processed model predictions to get all the other model modules and lesions
load('../Data/Data.Rdata', verbose = T) # This is one big df, 'data', 2580, of 215 ppts
data <- df2
mp <- read.csv('../Data/modelData/tidied_predpn.csv') # 576 of 26 - 576 rows because: 3 pgroups x 12 trialtypes x 4 nodes x 4 prior possible settings of unobserved variables
mp$pgroup <- as.factor(mp$pgroup)
mp$node3 <- as.factor(mp$node3)
mp$trialtype <- as.factor(mp$trialtype)
mp$structure <- as.factor(mp$structure)
mp$E.x <- as.factor(mp$E.x)
mp$E.y <- as.factor(mp$E.y)
# TO DO later - get the comments from the Rmd file and put them in here as well
# Condition 1
mp <- mp |> #
mutate(Actual = case_when(
node2 == 'A' ~ A==E.x,
node2 == 'B' ~ B==E.x,
node2 == 'Au' ~ Au==E.x,
node2 == 'Bu' ~ Bu==E.x
))
# Condition 2 - many of these are already caught but just to catch the extras
mp$Actual[mp$A=='0' & mp$node3=='Au=1'] <- FALSE
mp$Actual[mp$B=='0' & mp$node3=='Bu=1'] <- FALSE
mp <- mp |>
mutate(cesmActual = cesm*Actual)
# FULL inc kindness #1
full <- mp |>  #1
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(full = sum(cesmActual*posterior))
# Unnormalised of course and not incorporating K / EMD yet
noAct <- mp |>  #2
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noAct = sum(cesm*posterior))
noInf <- mp |>  #3
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noInf = sum(cesmActual*PrUn))
noActnoInf <- mp |>  #6
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noActnoInf = sum(cesm*PrUn))
getpost <- mp |> # 120 obs of 4
filter(!node2 %in% c('A','B')) |> #
group_by(pgroup, trialtype, node) |>
summarise(post = sum(posterior),
prior = sum(PrUn),
tv = round(abs((post-prior)),3)) # Maybe don't divide here by 2? Because both Au=1 and Au=0 need the value separately
postmp <- merge(mp, getpost, by = c('pgroup', 'trialtype', 'node'), all.x = TRUE)
# For A and B, gives 1 when E matches, 0 if not. This sets B to 1 for actual cause, eg. if B=0 when E=0
postmp <- postmp |>
mutate(Act1 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post,
node2 == 'Bu' ~ post
))
postmp <- postmp |>
mutate(noSelect = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post*Actual,
node2 == 'Bu' ~ post*Actual
))
noSelect <- postmp |> #14
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noSelect = mean(noSelect))
noActnoSelect <- postmp |> #14
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noActnoSelect = mean(Act1))
mp <- mp |>
mutate(Act3 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ peA*Actual,
node2 == 'Bu' ~ peB*Actual
))
noInfnoSelect <- mp |> #10
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noInfnoSelect = mean(Act3))
mp <- mp |> #
mutate(Act2 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ peA,
node2 == 'Bu' ~ peB
))
noActnoInfnoSelect <- mp |> # no act here means for the unobserved variables
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noActnoInfnoSelect = mean(Act2))
df_list <- list(full,
noAct,
noInf,
noSelect,
noActnoInf,
noActnoSelect,
noInfnoSelect,
noActnoInfnoSelect)
models <- df_list |> reduce(full_join, by = c('pgroup', 'trialtype', 'node3'))
Actual <- mp |> select(pgroup, trialtype, node3, Actual) |> unique()
models2 <- merge(models, Actual, all.x = TRUE)
# ------------- 2. Summarise participant data in same format ---------------------
# First set factors so we can use tally
data$pgroup <- as.factor(data$pgroup)
data$node3 <- as.factor(data$node3)
data$trialtype <- as.factor(data$trialtype)
# dataNorm <- data |> # 289
#   group_by(pgroup, trialtype, node3, .drop=FALSE) |>
#   tally |>
#   mutate(prop=n/sum(n))
# r
dataNorm <- data |>
group_by(pgroup, trialtype, node3, .drop=FALSE) |>
tally() |>
mutate(prop=n/sum(n))
tv2 <- getpost |>
select(pgroup, trialtype, node, tv) |>
rename(node3 = node)
# Merge with data just because it's needed across all models so best do it once here
dataNorm <- merge(x=dataNorm, y=tv2, all.x = T)
# ----------- 3. The actual merge! ------------
modelAndData <- merge(x=dataNorm, y=models2)
modelAndData <- modelAndData |>
unite('pg_tt', pgroup, trialtype, sep = "_", remove = FALSE)
#modelAndData <- modelAndData[, c(1:4, 7:12, 5, 13:16)]
modelAndData <- modelAndData |>
group_by(pg_tt) |>
mutate(baseline = 1 / n())
## ---------------------------------------------------------------------------------------------------------------
save(modelAndData, file = '../Data/modelData/modelAndDataUnfitpn.rda')
m
source(knitr::purl('optimise_withKandEps.Rmd'))
formatR::tidy_pipe()
